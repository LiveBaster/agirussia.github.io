## 15 февраля 2024 - Объектно-признаковые данные_ от философии до визуализации - Алексей Незнанов — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/hbcDZIZhdhM/hqdefault.jpg)](https://youtu.be/hbcDZIZhdhM)




S05 [00:00:03]  : Коллеги, всем добрый вечер. У нас сегодня на семинаре русскоязычного сообщества разработчиков сильного искусственного интеллекта Алексей Незнанов и он расскажет нам про объектно-признаковые данные от философии до визуализации через математику и программирование. Алексей, пожалуйста. 

S02 [00:00:22]  : Добрый день, коллеги. Давайте мы сегодня с вами посмотрим на совершенно то, что называется данными. При этом я очень люблю с точки зрения понимания того, что такое данные, знаменитую книгу, да, про данные. Но я, понятно, потом расскажу. А сейчас мы посмотрим, с чего все началось. Кстати, сразу здесь. А именно, у нас в чате как-то одно время был очень интересный разговор о том, что такое атрибут. И когда мы начали обсуждать этот атрибут, мы, естественно, упнулись не только в онтологические проблемы, но и во многие другие. И в результате мне захотелось как раз кусочки того, что увязывается не просто с атрибутом, а именно с объектно-признаковыми данными по-русски или объектно-атрибютными данными по-английски, каким-то образом дополнительно систематизировать с точки зрения их приложений, а не просто обсуждение их понятий или концептов. При этом как раз мы где-то в 2018 году занимались тем, что развлекались полноценным переводом на русский язык многих вещей, связанных с науками о данных. И как раз в том числе Переводили как обычные утверждения типа data mining. Добыча данных, наверное, не очень звучит, а давайте введем на русский mining и подскажем, что это mining данных. А с другой стороны, занимались основами всего этого дела. Говорили, что пусть у нас у атрибута есть очень много синонимов, включая коммутационный. Мы вытащили в свое время спаму 43. Но потом их осталось 27, а потом 23. На этом слайде у нас из них базовые приведены. При этом как раз они почти все, кроме двух, имеют русские эквиваленты, которые почти так же и называются. То есть акцент, аспект, атрибут, характеристика, условие и так далее. Что интересно, я здесь выделил цветом то, что очень важно с позиции математики. и как раз с позицией обсуждения свойств на естественном языке. В результате у меня здесь выделились condition predicate, да, и выделились kind, trait, type с точки зрения именно систематизации, и, естественно, базовые понятия, атрибут, да, свойства и как раз признак, то есть attribute, property, feature. Что важно? Важно, что как только мы начинаем говорить о каких-то данных, то я на этом даже не буду останавливаться. Мы, естественно, говорим о том, что данные — это информация, представленная в виде достойном и возможном для помещения в компьютер или голову человека, и таким образом у нее обязан быть носитель и все остальное. Именно поэтому мы почти не будем говорить про информацию, и более того, Если посмотреть как раз на то, какие у меня исходные источники были тем, что нельзя не знать, это, естественно, кусок логический, он начинается с теории Дальше кусок анализ формальных понятий. Он начинается естественно... 

S05 [00:04:43]  Алексей, извините пожалуйста. Жалуются несколько человек, что голос очень глухой. Там нет возможности как-то попробовать? 

S03 [00:03:54]  : Есть. На самом деле причем по-разному. Потому что у меня и сам голос плохой. 

S02 [00:03:59]  : Можно сделать вот так. ты что раз раз не переключишься это у меня произошло видать нет так-то в принципе слышно просто глуховатый голос можно было бы лучше я понимаю чуть не включается внешнюю систему сейчас секунду давайте мы его перенесем а можете что-нибудь сказать 

S05 [00:04:43]  : 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 5, 6. А вот сейчас лучше слышно? Примерно так же, на мой взгляд. Примерно так же. 

S04 [00:05:19]  : А если поближе к микрофону? 

S03 [00:05:22]  : Да уж куда ближе. Погодите тогда буквально секундочку. 

S03 [00:06:28]  : Если он включится, то будет замечательно. 

S05 [00:06:31]  : Гораздо лучше. 

S03 [00:06:32]  : Замечательно. Тогда мы сразу проверим, что не он включился и продолжаем. Да, спасибо большое. Спасибо за замечание. Здесь как раз анализ формальных понятий, который по сути начинается так же как с логика, с теории множества, с упорядоченных множеств и частично упорядоченных множеств, после этого, да, по-английски, partially moderate. получается очень хорошей надстройкой, которая позволяет формализовать почти все то, о чем мы с вами будем говорить. Ну и, наконец, с точки зрения того, что сейчас делается в информационных технологиях, база была заложена естественной революционной моделью. Причем мне очень нравится сравнивать революцию представлений. Здесь первый источник — это знаменитая первая статья Кода на эту тему. 1970 года. Дальше как раз его базовый, по сути, учебник-справочник Relational Models for Database Management, который как раз содержит полное описание, comprehensive study, всего, что он хотел сказать по этому поводу. Дальше знаменитая работа Дэйта про нормальные формы. Она уже достаточно свежая. И, наконец, замечательнейший просто учебник-расправочник Манкоса по концептуальному моделированию и переходу к базам данных. Я его до сих пор считаю лучшим, хотя прошло уже почти 10 лет. Почему? Потому что он очень четко и по полочкам раскладывает именно алгоритмический подход к моделированию, начиная с компьютера. Важно понимать, что ничего похожего на Манкоса, да, с каких-то других изводов я, в принципе, не видел. Можно это, кстати, отдельно обсудить. Это очень интересный вопрос. Ну, и получается, что мы, когда с вами говорим про то, о чём говорим. Сначала должны понять, откуда появляются сами объекты и признаки или атрибуты. И здесь очень важно, что я не буду глубоко залезать вот в этот кусок. Я залезу в прикладной больше намного, но о нем нельзя не сказать. Почему? Потому что нам нужно понять, откуда берутся сущности, и как раз понятие entities and concepts. Понятно, что с точки зрения того, откуда появляются конкретные атрибуты, нам необходим герминистический круг и, соответственно, эпистемологические основания. И дальше нам, естественно, очень важно понимать, а при чем здесь философия. И почему на естественном языке многие вещи невозможно, в принципе, сказать. И вообще, это одна из, с моей точки зрения, родимых таких черт философии, когда почему мы вообще должны думать, что естественным языком, например, русским или английским, можно выразить какую-то истину о нашем мире. С чего это мы взяли? Ну и получается, что нужно обязательное заземление, grounding. Это, кстати, сейчас снова стало на хайпе. Почему? Потому что у нас искусственный интеллект, придя к большим языковым моделям, а потом и к сверхбольшим языковым моделям, вынужден был возвратиться к физичности представлений о том, о чем мы думаем. Что важно? Если рассмотреть тот самый герметический круг, который наверняка все очень хорошо знают, то последовательные уточнения наших представлений и объяснений, engagement, understanding в одном смысле, или как раз преобразование симбольных систем в другом смысле, которые у нас идут с довоенных времен, до Второй мировой войны, Очень много дали для понимания того, что только в процессе некого спирального развития мы можем уточнять наши понятия. И эти понятия, оказывается, при наземлении уточняются именно как раз признаками каких-то объектов. Где, естественно, нужно выделить эти объекты из окружающего мира, а признаки концептуализировать, как говорят, или включить в ранг понимаемых нами понятий. Почему? Потому что, как здесь красиво написано, да целая или жизнь в целом — это что-то неовеществляемое, не на каком из уровней. В этом смысле герметический цикл бесконечен, и, соответственно, сейчас спиральное восхождение тоже. Про диалектику, наверное, сейчас не будем. Что важно, я здесь как раз хотел написать очень большой кусок именно антологический, но пока не стал, и так слишком много всего получилось. Я его, если надо, потом отдельно верну, потому что это просто отдельная презентация. А вот дальше что важно, это то, откуда берется определение признаков, которые входят в объекта признаковые данные, и почему мы говорим, что одни признаки лучше, чем другие. Понятно, что еще с треугольника Фреге, это верхний кусочек здесь на слайде. Мы, в общем-то, достаточно неплохо договорились о том, что в знаковых системах, которыми занимается семиотика, у нас есть некий знак или наименование в этой системе, которое выражает какой-то концепт, то бишь понятие, определяет генотат, и концепт, понятно, когда как понятие утвержден, то денатат можно связывать с любым объектом и восходить обратно, раскрывая этот треугольник. Потом было очень важное дополнение, которое с очевидностью приводит нас к тому, что не всегда мы можем, например, правильно понять то, что нам пытается сказать искусственный интеллект, и наоборот. 

S02 [00:12:13]  : Извините, я очень извиняюсь, вы листаете или нет? Потому что висит четвёртый слайд. 

S03 [00:12:21]  : А сейчас девятый. 

S02 [00:12:23]  : Ну так как-то это... Покажите, пожалуйста, другие слайды. 

S05 [00:12:29]  : Мы видим четвёртый по-прежнему. Прикольно. 

S03 [00:12:31]  : Это Zoom. Сейчас я попробую его StopShare и по новой. Спасибо за сообщение! Привет! 

S05 [00:12:59]  : Да, треугольник в фрифреге. 

S02 [00:13:02]  : Замечательно. 

S04 [00:13:03]  : Теперь девятый вы нам покажите, пожалуйста, хотя бы мельком. 

S03 [00:13:08]  : Да, значит, мы рассматривали как раз герметический цикл с точки зрения общего и как раз языковых систем. До этого рассматривали как раз собственно только начало. Так, а четвертый, это был еще вот, да, значит, а это был как раз кусочек, связанный с тем, с чего мы начали подход к снаряду, и синонимы слова attribute или признак, который входит в определение объекта на признаковых данных. Соответственно, потом мы к онтологиям вернемся, когда мы сказали, что договорились по треугольнику Фреги, и потом семиотики очень много чего наделали, мы решили, что с точки зрения естественных языков невозможно им ограничиться, и как раз у нас появляются коннотации. Без них практически невозможно работать ни в какой даже технической системе с признаками. Почему? Потому что, как мы потом увидим описание как раз неких понятий в виде наборов тех самых признаков, требуют уточнения с точки зрения наших мифов, именно социальных имеются в виду, и наших представлений о том, что какое-то понятие почти всегда ассоциативно влечет за собой другое. Причем, кстати, эти ассоциации, они началом имеют не само понятие, а как раз денататы, то есть объект, который нас окружает, который используется в коммуникации, например, в конкретном диалоге и так далее. В результате именно ассоциации, на которых работает наш мозг в том числе, среди прочего, здесь раньше были очень интересные обсуждения этого, оно нас приводит как к самому понятию коннотата и коннотаций, так и к тому, что мы считаем ассоциации субъективными, и возникает то, что нам потом надо будет каким-то образом разгребать, а именно, что признаки, даже которые очень четко формализованы до уровня физики и конкретных единиц измерения, все равно могут по-разному трактоваться и вызывать разные коннотации у как раз людей с точки зрения прагматики. Дальше как раз у нас тут как раз был очень большой кусок того, что нужно по естественному языку. Мы сейчас тоже к нему обратно перейдем. Но сначала придется формализовать понятия-понятия и как раз указать, откуда берутся с точки зрения математики сами признаки. При этом, что важно? Сейчас у нас вышли новые работы, которые становятся новым поколением описания того, что из себя представляет не только анализ формальных понятий, но и все связанные вещи, и поэтому обращаться непосредственно к 72-му году Вилле, а потом как раз к 80-му и Гантуру уже необязательно. Что важно, у нас недавно, когда мы обсуждали с коллегами, что мы хотим сказать, если хотим описать анализ формальных понятий в целом, то лучше всего сначала просто сказать, что это преклонная теория решеток, а потом сказать, с чем она связана и как. И вот здесь что интересно, проще всего сразу открыть Такую вот штучку веселую. Так, а где она? Вот она. Бэмс. 

S03 [00:16:50]  : Простите, коллеги, сейчас. И как раз сказать, что совсем недавно, полтора года назад, у нас вышло новое очень хорошее введение о том, что это такое на базовом уровне для более-менее обычного человека, который имеет базовые математические знания. И что особенно интересно, у нас после Гантера появилась очень маленькая система спецификаций основных определений в анализе формальных понятий, и мне как раз тоже очень нравится так называемая немецкая аннотация этого. Почему? Потому что она позволяет это отделить от классических теоретиком множественных представлений, поскольку они все равно на них как раз заземляются, и сказать, что у нас замечательно просто работает базовая концепция оператора голова, замыкание, да, и как раз того, а почему мы считаем, что на этом базисе можно, в принципе, описывать понятия. Дело в том, что как только мы говорим о частично упорядоченных множеств и потом строим стандартные решетки, то мы всегда можем, и это теорема, рассматривать их как соответствующий формальный контекст. А именно, мы говорим, что у нас формальным контекстом называется матрица, которая состоит из объектов и признаков, и появляется отношение принадлежности к признаку объекту. Что важно, здесь само по себе появляется понятие объекта как такового, А раз появляется понятие объекта, то мы сводим опять задачу понимания объектно-признаковых данных к чему, а откуда этот объект может браться. И здесь мы, как часто в математике, говорим, что объект — это просто элемент некого множества, и дальше физику этого множества оставляем на интерпретацию. То же самое и с множеством атрибутов или признаков. После чего говорим, что нас интересуют именно взаимоотношения между объектами и как раз признаками. И главное, что мы можем сделать, это формально определив формальный контекст протезиофтофтологии, сказать, что если объект обладает каким-то атрибутом, то есть признаком, то мы дальше можем прекрасно определить формальное понятие которая как раз определяется очень просто. Мы говорим, что есть подмножество объектов, подмножество признаков, которое образует пару, именно она становится понятием, и как раз есть тривиальное, по сути, обратное свойство. Мы, императором Гула, у объектов берем признаки, а у признаков берем объекты. Таким образом, если рассмотреть матрицу и отсортировать ее так, что объекты будут рядом, признаки будут рядом, то это будет полностью заполненная матрица как раз отношения i, иметь признак m у объекта b. Здесь есть очень симпатичный новый пример, который сразу иллюстрирует и объекты, и признаки, и как раз решетку вместе со шкалированием. Почему? Потому что как только мы занимаемся интерпретацией наших признаков, естественно, объектов, то возникает проблема. Если мы еще раз рассмотрим определение, то мы увидим, что там у нас есть аппарат бинарных отношений, И в результате получается, что на пересечении объекта и признака может стоять только, по сути, булево значение «да-нет». В данном случае «нет» — пусто, «да» — это галочка или крестик. Что важно, стандартно мы рисуем объекты по вертикали, да, признаки по горизонтали, и уже здесь видно, что признаки становятся какими-то хитрыми. А именно возникает то, что всем специалистам в области машинного обучения известно, да, как one-hot, one-stop encoding, да, когда мы говорим, что некий, например, размер, который может быть вещественным числом, мы шкалируем и тем самым получаем бинарные признаки. Например, в данном случае, да, маленький, большой, средний. И вопросы шкалирования становятся отдельной очень большой областью, когда мы с вами пытаемся формализовать любые признаки в любых целях. Почему? Потому что в принципе не бывает признака без привязки какой-то шкалы, если это полезный признак. И как раз мы в любом случае в каких-то условиях будем вынуждены свести этот признак к набору бинарных признаков, которые позволят нам распределить объекты по некоторому пространству. Таким образом, здесь и размер отшкалирован, и расстояние до Солнца отшкалировано. И наличие Луны не отшкалировано, поскольку это уже бинарный признак. Но, естественно, если бы это было, например, количество Лун, то мы бы тоже его отшкалировали каким-то образом, превратив в бинарные. Дальше понятно, что мы можем вытащить теперь из этой матрицы какой-то кусочек, полностью заполненный, и получить решетку. У нас с точки зрения решеток есть линейная диаграмма, да, есть диаграмма частичного порядочного множества, и есть, наконец, вполне себе достойные варианты визуализации, когда мы ограничиваем что-то, попавшее в решетку, и, например, здесь мы говорим, что у нас есть упрощённое или редуцированное представление, когда мы не на всех понятиях пишем то, из чего они состоят, а пишем только там, где это нам важно, где они впервые появляются. Таким образом, мы получаем что-то аналогичное дереву решений, когда, начиная с корня, мы принимаем решение, к чему относятся у нас объекты относительно пространства признаков. и говорим, что здесь у нас то, что small по сайзу, а в другую сторону то, что есть по муну. Ну и так далее спускаясь, соответствующая решетка в реальных случаях может быть огромной, мы приходим к каким-то наборам объектов и всех признаках на том пути от вершины, по которым мы спускались. Тем самым мы конструктивно строим, во-первых, Extent, во-вторых, Intent, то есть множество объектов и признаков, составляющих понятие. Обычно их ассоциируют с чем? С объемом и содержанием, которые идут еще от Аристотеля. Почему? Потому что если мы укажем, например, что есть планеты внутреннего пояса, планеты среднего пояса и так далее, то как только мы как-то называем набор объектов, то мы автоматически называем и набор признаков которые приводят к этому набору объектов из исходного формального контекста, и тем самым автоматически строим содержание в смысле как раз набора признаков и объем понятия как набор объектов. Это, с моей точки зрения, на текущий момент одно из лучших автоматических представлений объекта признаковых данных. Почему? Потому что из любого либо естественно-языкового, либо физического представления о каких-то объектах мы обратно всегда можем построить какие-то из признаков, и тем самым понять, какие признаки как формально должны быть устроены, чтобы породить нужное нам понятие. Например, если объекты — это у нас животные, Васька, Барсик и так далее, а признаки — это там четырехлапость, такая-то шкурка, такие-то хвосты, такие-то уши и все прочее, признаков на самом деле тоже огромное количество может быть, то, назвав некое понятие «волк», мы тем самым сразу говорим, что у нас есть огромное количество конкретных животных, которых мы называем волками, и, естественно, какие-то наборы признаков. Что интересно? Отсюда очень интересные две связи с как раз data mining тем самым, добычей данных, и ассоциациями, импликациями в контексте. Здесь как раз в любом случае это есть, причем очень симпатично, с точки зрения того, что как только мы говорим про импликации как логическую операцию, мы тут же говорим, что это вполне естественная физическая и вполне заземленная операция на признаках. Почему? Потому что как только мы их вывели из каких-то нужных нам понятий, то мы на них можем строить соответствующие отношения, и импликации в контексте становятся тем, что позволяет нам определять, какого конкретного качества будут наши объектопризнаковые данные, и что мы из них можем вытащить. В том числе, можем ли мы из них вытащить какие-то правила, которые позволят нам валидировать эти данные и, соответственно, куски реальности, которые эти данные описывают. Что интересно, это то, что если посмотреть, как у нас устроено здесь, например, представление о отношении, давайте вот так его нарисуем, то мы знаем, что в английском языке есть два разных слова, это очень удобно, «relation» и «relationship». В русском, к сожалению, это не так, и сейчас мы к этому вернемся. И с точки зрения революционного и алгебро-революционного счисления, отношения — это у нас схема отношений плюс наборы картежей, которые соответствуют в каждом своем элементе атрибутам или как раз признакам из схемы отношений. Таким образом, автоматически можно сказать, что мы, получая отношения в революционном смысле, получаем также и формальный контекст Отмечу, что ни там, ни там никакого порядка нет. Это все всегда знают, но иногда забывают на практике. И что самое интересное, мы всегда можем сопоставить сами признаки, как их одинотат, с тем, какому понятию с точки зрения пространства признаков они соответствуют. И это будет как раз описание метаданных. К метаданным мы еще как минимум два раза сейчас вернемся. Что дальше интересно? Когда у нас получается, что есть отношения, мы всегда можем теперь сказать, а у нас есть то, что является импликациями в контексте, и здесь оно называется функциональными многозначными зависимостями. Хлоп. При этом На самом деле это одно и то же, только с разных кусков математики. что у них получается общего. А общего получаются те как раз стандартные свойства от рефлексивности до декомпозиции и, естественно, правила Армстронга, построение одних правил на основе других правил или как раз преобразование импликаций. Более того, как только мы разобрались с импликациями, Отмечу, что в реальном мире пошли дальше, чем просто функциональные зависимости, и у нас появились многозначные зависимости. Пока их откладываем в стороны. И дальше мы говорим, а может ли быть у нас не импликация, а как бы нечеткая импликация, которая влечет за собой с какой-то вероятностью наличие признаков у объектов. И да, у нас появляются ассоциативные правила. И как раз после того, как мы можем описать в целом то, что происходит с объектами-признаками, мы можем описать интервальные структуры. или узорной структуры, или интервальной узорной структуры, и потом все время увеличивать нагрузку на каждое формальное понятие, говоря, что его признаки — это все более сложные структуры, а не просто бинарный признак. При этом, что характерно, если посмотреть на то, как у нас представляются решетки, опять-таки уменьшенные с точки зрения объектов и признаков в целом, то мы увидим, что с одной стороны у нас есть максимум, с другой минимум. Ну и понятно, что если мы выбрали такую подобность, в которой работаем, где есть какой-то общий признак вообще для всех объектов нашей области, он, естественно, сохранится как общий. И мы о дальнейшем рассмотрении именно этой подобности можем просто его не учитывать, считая, что зачем нам рассматривать один какой-то общий или там несколько общих признаков, если они не дистанцируют наши объекты. и тем самым их никак не различают. Что важно? Когда мы как раз говорим, что есть тот из вот этот, то есть аналитическое понятие, которое пришло из частично упорядоченных множеств, и как раз революционное алгебра, революционное счисление, которое пришло от специального расширения логики на кортежах, мы понимаем, что можно сделать реляционный анализ понятий и как раз объединить эти вещи в одну. Что интересно, это то, что мы автоматически закладываем базис не просто для определения понятий, но еще и для того, чтобы нормально, включая как раз все там правила Амстронга, функциональные зависимости, многозначные зависимости, перевести на язык частично-порядочных множеств, и затем сказать, что какие-то из них есть априори заданные в контекстах и, соответственно, отношениях, какие-то случайно там образуются, и, собственно, мы их и ищем путем майнинга данных. И главное, что можно как раз соединить тем самым оба мира, и значит оба Шапира нам дадут, что возможность единообразно сделать так называемую инженерию признаков, которая сейчас всегда становится составной частью, например, классической инженерии признаков Feature Engineering в ML, в машинном обучении. Бабах, оказывается, это все одно и то же, если рассматривать сами алгоритмы, а не формальные определения базовых понятий. Формальные же определения базовых понятий переходят друг друга абсолютно изоморфно, и, что особенно важно, это вполне доказуемый теоретик. Поэтому, когда мы видим схему контекстов или схему понятий с точки зрения базы данных, которой у нас, как известно, есть структурный аспект, манипуляционный аспект и целостностный аспект, то мы вполне можем замещать нормализованное отношение на как раз контекст, замещать алгебру на как раз специальное подно, что операции с обязательным включением оператора Голуа из операций над упорядоченными, частично упорядоченными множествами. И целостный аспект самый интересный. Там мы вместо внешних ключей должны что использовать? Должны использовать как раз вариант перехода ассоциированных правил в импликации. Вот такая вот интересная штука. Что еще интересно, это то, что можно потом сделать виды классификации объектов, которые прекрасно работают с именами на формальных понятиях. Тем самым всю классическую систематизацию примерно на рубеже 90-х до 2000-х годов преобразовали так, чтобы она, во-первых, была внутренне непротиворечивой и, во-вторых, нормально мержилась, соединялась или гармонизировалась с соседними классификациями систематизациями. И что в итоге получили? Получили возможность проверить наши представления о том, что великие гранды 18-19 веков, в первую очередь, наделывали в животном мире, растительном мире, в минералах, и мы все это поправили. И одно время мне приходилось отвечать на вопросы студентов, а почему у нас там изменился животный мир и все его там царства, роды, виды и так далее. Я говорю, потому что у нас появилась генетика, плюс появилась как раз новая нормальная математика, которая позволяет нам таксономические отношения в первую очередь переопределить так, чтобы как раз не было никаких гадостей, избавившись от гадостей и всевозможных парадоксов, мы получаем автоматизацию. И теперь компьютер, ничуть не хуже наших самих, нормально работает с понятиями, если под ними понимать как раз пары всё уже, содержание понятия да и объём понятия, Extent-Intent, и, что важно, дальше у нас появляются эксплицитные и имплицитные свойства такого представления. Это первый кусочек, который особенно интересен с позиции чего? С позиции того, что ко всему этому можно подойти абсолютно единообразно. Более того, в современной логике, особенно если как раз пойти и вот сюда вот щелкнуть в Open Logic Project, у нас есть просто замечательнейшая вещь. Наверняка все присутствующие хоть краем глаза видели такой знаменитый проект, который по сути представляется бы опять-таки учебник-справочник по всему объему логических знаний накопленного человечества, хотя некоторым форма не нравится. И посмотреть можно, из чего он состоит. Взять как раз на сайте, который содержит готовые куски И посмотреть, что да, у нас в начале есть теория множеств. Дальше есть некий интермедиат кусок. И как раз дальше есть очень интересная добавка, которая очень-очень длинная, и которую разбили на очень большие отдельные кусочки. Что при этом интересно? Интересно то, что с позиции, например, онтологического описания мы можем смело теперь делать либо описание на какой-то простейшей логике, например, вообще на основе теории множества как таковой, да? либо на все более усложняющихся логиках, естественным образом через дискретивные логики, в которых нам нужен боксинг, и вплоть до модальных логик, да, с кучей миров и так далее, все более интересные системы вывода из наших описаний понятий, А поскольку в основе всегда лежат те самые либо формальные контексты, либо отношения революционные, то мы и так, и так приходим к чему? К объектно-признаковым данным с точки зрения компьютера, который их представляет естественно некоторыми таблицами, хотя на них нет порядка, ни на объектах, ни на признаках. Надо ли что-нибудь здесь прокомментировать? Или пойдем дальше к приложениям? 

S05 [00:36:35]  : Ну, здесь довольно много вопросов уже возникло. Можно попробовать на них ответить, а можно двигаться дальше. 

S02 [00:36:44]  : Окей. 

S05 [00:36:47]  : Вот у меня сразу вопрос, вот вы недавно говорили про поженить, вот с большим удовольствием слушаю, и вопрос, когда вы пытаетесь поженить революционную алгебру и формал-концепт-анализ, вы как-то предусматриваете, чтобы при этом еще поженить вероятностные аспекты? 

S03 [00:37:11]  : Конечно, но это чуть позже. Более того, здесь очень хороший вопрос про нечёткие логики. Вот сейчас я проговорил о детерминированной логике, вплоть до модальных. А как раз дальше мы будем говорить, а если граундинг нас заставляет работать с реальным профизическим содержанием, и у нас есть нечёткость исходная, Что делать? Естественно, нужны будут нечёткие логики. И более того, как раз с точки зрения анализа формальных понятий, именно для этого во многом мы перешли от классических, извиняюсь, что-то я слишком далеко ткнулся, контекстов к узорным структурам. Сейчас. Вот они, да, pattern structures. На русский как раз довольно тяжело перевести. И в свое время Сергей Олегович предложил, что пусть это будут узоры, в отличие от шаблонов. Так оно и прижилось. Почему? Потому что они естественным образом, например, в виде как раз интервальных узорных структур представляют собой нечеткость. Ну если обычные интервалы, то это как раз с распределением равномерным. Если на них наложить еще распределение и будет интервал плюс распределение, можно делать с нормальным и каким угодно. И тем самым мы что получаем? Шкалирование, которое теперь может быть сколь угодно сложным. То есть мы можем вначале иметь как раз исходник в виде бинарных как раз признаков. И, соответственно, просто обладает ли объект признаком. Потом, да, обладает ли объект признаком, выражающимся, там, допустим, числом обычным. Потом, там, каким угодно числом, естественно, вплоть до кватернионов. А дальше, обладает ли объект, например, да, последовательностью каких-нибудь графов. Или графом, с гиперграфом, у которого есть веса вплоть до каких-нибудь тоже графов. Понятно, что дьявол в деталях, и важно, как мы будем этим оперировать. Но описание, то есть representation, оно становится, в общем-то, абсолютно универсальным. При этом как раз с точки зрения аддитивности все получается замечательно. Почему? Потому что мы вполне говорим, что когда рассматриваем объекты и признаки каким угодно способом, то всегда наличие какой-то здесь значка, оно, по сути, с точки зрения физики, в моей, правда, сейчас простой интерпретации, это можно вывести на уровень тоже отдельный под теорией. Кстати, вывели, коллеги, да? К чему приводят? К тому, что у нас появляется в физическом мире нечто, что обязывает иметь проверяемые следствия из того, что, например, земля такого-то размера. И мы говорим, что если мы теперь в телескоп посмотрим, то мы увидим то-то, то-то и, соответственно, подтвердим эту галочку. А здесь, соответственно, не подтвердим галочку. В результате, каждая как раз, по сути, простановка соответствующей галочки как кусочка объектно-признаковых данных исключительно физична. Эта операция почти во всех изводах, которые я знаю, автоматически влечет за собой возможность физической проверки. А там, где не влечёт, это обычно всяческие парадоксы, и на практике, например, я с таким вообще не сталкивался. Вот эта небинарность, это к чему было? А не слышно. 

S05 [00:40:43]  : Вопрос докладчику. Бинарность признаков у вас абсолютная или относительная? Если измерять все, к примеру, относительно Марса, то Земля уже не будет маленькой. 

S03 [00:40:52]  : Обязательно относительная. Почему? Потому что мы, когда делаем шкалирование и говорим, что был размер, и он, например, был в астрономических единицах, или в метрах, или в чем угодно, то дальше мы должны указать границы между маленьким и средним. и отсюда как раз необходимость на практике часто перехода к нечеткости когда мы говорим а мы не знаем точно где кончается маленький начинается средний Более того, мы во многих случаях должны сказать, что маленький, например, от 0 до 100, средний от 100 до 200, большой от 200 до бесконечности. И возникает вопрос принадлежности границ. то есть 100 это маленький или уже средний да возникает вопрос о том а если мы с погрешностью меряем то как это отражается на шкале и наконец самый веселый вопрос что в любом случае все эти названия например маленький средний большой должны быть тоже заграундены и они ссылаются в данном случае на сайс почему он здесь и приведен, да? И нельзя просто написать small, а не написать size. И такие иерархии обычно бывают еще длиньше. В этом смысле характерна современная онтологизация единиц измерения. Мне, например, нравится больше всего знаменитый, давайте я его прям открою, он в любом случае интересен, вдруг кто случайно не видел, да? Это Вот. 

S03 [00:42:31]  : И у коллег прямо на первой же страничке Есть что? Есть кроме базового писания и ссылки на RDF файл, да? Классическая иллюстрация. А, единственное, она нехорошая. Сейчас мы её сделаем белой. Вот. Умс. Что мы видим? Мы видим, что в этой онтологии у нас система единицы измерения, которая состоит из самих единиц измерения, предназначена для того, чтобы какие-то количества считать, что вполне естественно. А дальше мы говорим, что именно к количествам относятся размерности, а в единице измерения появляются именно измерения. И видите, здесь прямой связи нет. то есть major has unit, да, а quantity и unit, да, соответственно, has quantity и common has unit. Такая вот интересная вещь. Это позволяет нам как раз и сказать, что есть диссигнаторы, то есть обозначения в языке, естественном, да, компьютерном, каком угодно, единиц, которые как раз позволяют задать шкалу. Вот она, шкала внизу. имеющие эти единицы, и тем самым, например, проводить автоматическое шкалирование. Мы говорим, что если у нас некие объекты имеют некие размеры, возвращаемся к картинке, да, и говорим, что они, например, там от 50 до 300, то давай мы их разделим, например, на 4 куска или на 5 кусков. Это настраивается, и тем самым шкалы, в большинстве случаев практически значимых, могут автоматически генерироваться. Когда не могут в реальности? Тогда, когда мы не можем установить априори некий универсум объектов и сказать, что он у нас поместится в такие-то значения размеров. Тогда, да, надо будет, скорее всего, потом переделывать эту шкалу. Но, тем не менее, если у нас есть базовая онтология того, из чего эта шкала состоит и как меряется, и, соответственно, ссылка, например, на ISO 80000, на всякий случай, у нас же есть вот такая штука, за которую можно заграундить. Вот. У нее куча подстандартов на все типы измерений. Ну и, собственно, когда я в практике сталкиваюсь с тем, что мне нужна какая-то очередная шкала, я говорю коллеге, нам нужно взять какой-то из этих стандартов, потом как раз сказать, взять, извиняюсь, взять антологию и завести это вот к такому виду, когда мы говорим, что любое значение, а это может быть бинарное значение, да, yes, no, это может быть число, это может быть строка, это может быть граф, гиперграф и что угодно, главное, что оно получает по этой шкале что-то, что позволяет его отнести к куску этой шкалы и тем самым бинаризировать. Вот. А, ну и про иерархию. Прямо здесь, по-моему, у коллег есть. Да, вот классика. То есть у нас есть то, что мы исследуем, и разрезы. Мы к этому сейчас перейдем, когда к бизнес-аналитике придем. Привычный вариант. И те самые разрезы у нас устроены относительно измерений абсолютно так же. То есть, например, стандартные корпорации, люди, занимающиеся аналитикой и работающие в биосистемах, делают это абсолютно так же. Так, дальше у нас кусочек… вот. Ну, в общем, естественно, это я согласен, единого «мы» не существует. Это мы как раз поняли. Это как раз то, о чем я говорил, что почти всегда на практике все работает, но потом мы можем попытаться случайно подойти к границам применимости каких-то моделей или границам применимости как раз наших текущих знаний и моделей, и сказать, что «упс, мы куда-то выперлись, о чем еще не знаем». И поэтому, когда мы открыли Луну и Питера, или как раз наоборот, помните, последние 10 лет все время мы Плутон, то туда, то сюда, то планета, то не планета, и так далее. Это все очень интересно с позицией как раз того, что на границах областей применимости любые шкалы начинают плыть. То есть, когда мы открыли ток электрический, а до этого о нем ничего не знали, то понадобилось этот ток измерить. Это вот об этом? 

S01 [00:47:13]  : – Не совсем. 

S03 [00:47:14]  : – А, давайте уточните. 

S01 [00:47:17]  : – Последний мой вопрос, что модели делаются под классы задач и распределяются по стратам. Одно дело модели элементарных частиц, а другое дело модели политологии. или экономики. 

S03 [00:47:37]  : Но это имеется ввиду модели оптимизации или модели решения задач? 

S01 [00:47:41]  : Нет, модели, вообще модели познания. У нас в нашей практике человеческой имеется множество различных классов задач на различном уровне абстракции. и с различным выходом на практику. И если мы занимаемся ядерной физикой, нам нужны одни модели, а если мы занимаемся экономикой, то другие. 

S03 [00:48:11]  : – Вот здесь, что особенно интересно, как раз в модели решения задач, то есть с моей точки зрения, которая делится на как раз кучу классов по таксономии, с одной стороны областей, с другой стороны методов. У нас действительно идут оттуда. А вот representation с точки зрения некого базового языка, особенно вычислительной техники, где-то как раз 2010-х уже годов, в общем-то, достаточно универсальны. Причем настолько универсальны, что, например, в текущей практической деятельности я не сталкивался с необходимостью менять репрезентации относительно вот этого универсального подхода, пожалуй, ни разу за последние лет 15. 

S01 [00:49:00]  : Я думаю, это связано с тем, что вы рассматриваете статические модели. 

S03 [00:49:05]  : Нет, не только, динамически тоже. 

S01 [00:49:07]  : Нет, не в смысле физики, а в смысле набора понятий и знаний. 

S03 [00:49:13]  : Нет, как раз динамически обязательным. 

S01 [00:49:16]  : Тогда у вас должны меняться наборы признаков и соотношения. 

S03 [00:49:21]  : Обязательно. То есть непрерывное как раз изменение мира и наших потребностей в этом мире, оно, естественно, приводит к изменению не просто того, что у нас какие-то объекты убираются, какие-то добавляются, а что как раз вводятся новые понятия, меняются понятия. И как раз коллеги, которые занялись тем, что можно ли сохранить связность репрезентации, то есть представления, Пришли к чему? К пониманию, что, например, на уровне самих понятий можно выделить так называемые наиболее интересные понятия, они называются Base-Level Concepts. 

S01 [00:50:00]  : Они интересны для одного класса задач, а для другого так интересны. 

S03 [00:50:05]  : Они универсально интересны, почему? Потому что они обладают максимальной дистинктивностью. Например, у Белохлавика это очень симпатично было изложено. А, мы сейчас не откроем, да, красиво, жалко. Значит, я тогда это самое отдельно дам ссылочку очень интересную. Почему? Потому что мы можем как раз в контексте, например, здесь сказать, что у нас какие-то из получившихся понятий, да, они менее дистинктивны друг от друга, например, с точки зрения признаков или с точки зрения объектов, соответственно, эксплицитно и принципно, чем другие. И мы почему, например, выделили понятие «волк» и понятие «собака», а не какие-то вместо них 2-3 других понятия? Ведь признаков, по которым мы отличаем, их огромное количество, их сотни. А скорее всего, и это было проверено очень для многих задач, мы как раз неявно и хотели, чтобы была максимальная дистинктивность понятий друг от друга, как с точки зрения множества объектов, так и с точки зрения множества признаков. 

S05 [00:51:11]  : моей точки зрения во многих задачах нам волк вообще не нужен борис алексей извините здесь у нас есть риск что сейчас у нас будет на час дискуссия вот поскольку у нас сейчас уже прошел мне хотелось бы убедиться что мы успеем послушать про вероятностные нечеткие аспекты 

S03 [00:51:36]  : свадьбы революционной алгебры с анализом формальных понятий поэтому может быть мы двинемся дальше а если еще как раз кусочек вопросов как минимум 2 до именно потому что мы как раз естественно можем потом сказать что набор объектов они объединяются в один объект И тем самым мы по уровням либо халархии, либо по уровням астракции прекрасно перемещаемся. Поэтому сейчас вернемся. Почему? Потому что, если как раз быстренько посмотреть на сами сущности, которые как раз у нас за собой где-то в другом измерении держат множество объектов, то понятно, что у нас есть информационные системы, в которые мы хотим впендюрить эту информацию о сущностях, и, естественно, у нас появляются стандартные задачи и как раз описание данных метаданными. Что имеется в виду? В простейшем случае, если как раз вот здесь посмотреть на названия и вот эти названия, они — это просто символы какого-то языка. Но если мы их сопоставим с какой-то онтологией, а еще лучше — с онтикой, как в редкой предметной области, то мы тем самым заграундим их в И как раз можем переходить по руне абстракций. Более того, вот эти ссылки на онтологию от того, что size — это размер, да, и мы знаем, что размер измеряется там в метрах или еще что-то, это как раз становится основной частью метаданных, которые с точки зрения работы компьютера, к чему нас приводят к форматам данных. а как раз то, откуда мы их можем получить, то есть наборы объектов, откуда у нас получаются, и как раз информация о признаках, у нас становится второй кусок метаданных. Это как раз то, что касается протоколов и интерфейсов обмена данными. И, о чудо, в современном мире вдруг оказывается, что все протоколы и как раз интерфейс обмена данными могут быть прекрасно представленными как обмен, чем объекта, признакуемый данными в виде вот таких табличек, правда, без порядка на них. Даже если это графы. Почему? Потому что любой граф — это обязательно матрица смежности графа. При этом возникает универсальное представление, и вот как раз вторая часть с этого начинается, что у нас появляется объект, который является экземпляром сущности, атрибут, который становится описателем и собственно ссылкой на как раз тоже атрибут сущности. И, соответственно, объект тем самым получается связан с одной стороны с метаданными сущностей, а с другой стороны тоже с метаданными сущностями другого вида атрибутами. признаками и как раз у нас возникают значения то есть у нас получается атрибут как наименование и атрибут как значение атрибута плюс еще очень часто рассматривают третий кусок как репрезентацию атрибута то есть представление в какой-то системе например как раз с каким-то типом с форматом данных тем самым получив диссигнаторы или ссылки на атрибуты, ссылки на объекты и значения атрибутов этого объекта. Да, мы получаем стандартные с одной стороны матрицы, но на которых нет еще раз никакого порядка, не устану это повторять. И дальше мы можем связать это со знаменитым объектно-ориентированным программированием. При этом, что интересно, в английском языке правильно все называется «object-oriented», а в русском есть «объекто» и «объектно». Но тогда сейчас не будем погружаться. И здесь, что важно, нам приходится понять, а что же такое как раз поведение, и особенно поведение во времени, чтобы у нас появились 4D-объекты на основе каких-то сущностей. И с точки зрения объектно-ориентированного подхода мы определяем классы, И, о чудо, у нас появляются стандартные отношения, которые тем самым могут быть прекрасно сведены к стандартным признакам в стандартных формальных контекстах. Даже если мы сейчас этот список расширим, а это стандартно из умейля, который я, так сказать, переопределил, мы можем спокойно брать любое отношение, говорить, какой оно арности. Единственное, как это теперь другому человеку сказать? Потому что каждый раз писать формулы для, например, узорных структур – это ужасно. простейших случаях, как мы будем поступать. К счастью, у нас достаточно давно есть понимание о том, что мы, двигаясь по иерархии абстракций, в том числе двигаемся по иерархии представлений. Обычно этих уровней больше, но эти три всегда есть – концептуально, логически, физически. то есть в физическом ничего не можем отвязаться с точки зрения реализации, на логическом отвязались от деталей физической реализации, чтобы была некая, как сейчас говорят, digital twin, да, математическая модель, и, наконец, на концептуальном уровне отвязались от этой математики так, чтобы другому человеку сказать на уровне понятий. Соответственно, как раз опять-таки в английском очень удобно, что есть relation, а есть relationship, А в русском это все отношения и революционные отношения, бинарные отношения, совершенно разные объекты, совершенно разных классов и типов. А здесь у нас все это нормально делается. Поэтому как раз очень тяжело переводить, кстати, иностранную литературу, потому что даже из словарей очень мало, что можно полноценно выцепить. И особенно от этого страдает как раз революционное, алгебро-революционное счисление. дальше мы говорим что у нас на конституальном уровне и вот здесь как раз важно для статических моделей помните был вопрос начиная с товарища чена и 76 года да появились что знаменитые диаграммы сущность связь здесь нормально исходно в россии до решили что этот релейшеншип быть будет связью ура ура и При этом, да, это именно статические модели с позиции чего? С позиции отсутствия фактора времени непосредственно в самой картинке. И мы говорим, что да, слева это первая нарисованная членом диаграмма для статьи, справа, как сейчас, они расширенно красиво рисуются, и действительно, на акцентуальном уровне, прекрасно, на ромбиках, понятно, и арность, например, здесь арность 3, и как раз модальность, множественность, и все остальное, что можно дополнительно дорисовать. Но это не переведешь в логику. Почему? Потому что такого рода связи… а это, естественно, можно тоже представить формальную конъекцию в стандартной матрице, потребуют ссылок на те самые онтологии, которых здесь не присутствует. Поэтому на уровень ниже в логике, в классических революционных базах данных, что мы делаем? Мы отвлекаемся от нормальной формализации отношений или связей в ERD, И говорим, что появляются натурализационные схемы или диаграммы, таблица, связь, хотя по-английски здесь reference, а не relationship и даже не relation, да? И говорим, что с точки зрения революционной алгебры они выражаются внешними ключами. На внешних ключах есть ограничения, ура-ура. То есть мы заменили правильное представление связей в любой арности с любыми модальностями и множественностями на внешние ключи, тем самым резко потеряли выразительность. Но зато приобрели как в простоте и эффективности, так и с точки зрения логичности, как и логических операций, в которых пришлось добавить всего две штуки. Это же было достижение выдающееся. А вот дальше, что интересно, мы говорим, даже если мы просто выбираем уровень и говорим, что у нас появляется, допустим, сущность связь и реляционная модель, то мы чётко говорим, для чего это предназначено. И по ходу можно сделать такой же совершенно кусок развлечения уровней абстракции и абстракции представлений в первую очередь для почти чего угодно, например, динамических моделей, взяв за основу либо как раз умыльные ActivityDiagram, либо как раз BPMN, до Business Process Modeling and Notation, или что угодно еще. В результате что получается? Мы как раз говорим, что пользователю всегда, так или иначе, компьютер предлагает эти объектно-признаковые данные, причем со ссылкой на метаданные. То есть обычно можно считать на 99% что это ссылки на элементы онтологии. И возникает очень интересная вещь. мы говорим, что появляется понятие электронной таблицы. И оказывается, этот концепт, то есть понятие, стало настолько удобным для разговора с любым обычным человеком, что мы почти любые примеры на преобразование данных можем прекрасно выкинуть, например, в Excel. Почему? Ну потому что, начиная еще с Lotus 1.2.3 знаменитого, мы решили, что взяв здесь как раз одно измерение объектов, другое измерение признаков, и добавив формулы, и добавив гиперссылки, мы получаем универсальный решатель, или Solver, любых вещей, связанных с такими матрицами, которые могут любые объектно-признаковые данные иллюстрировать. При этом понятно, что без полноценной, более серьезной алгебры, например реляционной, и соответствующих там отношений, нам не жить. И что мы делаем? Мы говорим, например, даже в Excel, который электронные таблицы, мы пришли ко встроенной базе данных и появились там таблицы. Терминология ужасная. Но по-английски нормально, потому что сначала был spreadsheet, а в него кладутся tables. Эти tables могут жить на самом деле отдельно от spreadsheets. Почему? Потому что встроенная база данных в Excel позволяет с ними работать, которые даже не помещаются на лист Excel. Почему? Потому что на рабочем листе Excel до миллиона строк примерно, а в таблице может быть сколько угодно строк. Я работал, например, там, где было под 100 миллионов строк, и ничего страшного. И нужно иметь какой-то вариант representation, то есть представление этого, которое позволяло бы человеку всегда это положить себе на лист и работать с ним с точки зрения интерфейса. И такое представление есть, тоже на него сейчас не будем отвлекаться. И главное, что Мы получаем набор вопросов о том, как совместить эти представления внутри компьютера с представлениями снаружи, то есть при визуализации. Понятно, что общие вопросы нас не так интересуют, как то, к чему мы сейчас пришли. В общем-то, обычно, когда об этом говорят, сначала говорят о знаменитой книжке Туффе 2001 года. Вот. Но сейчас появился очень клёвый источник позапрошлого года, да? Introduction to Visual Data Sensemaking, да? То есть, чтобы смысл делать. И в чём этот, собственно, смысл? В том, что мы начинаем всегда влезать от тех же самых таблиц считая их, да, с точки зрения математики, как раз теми самыми контекстами или революционными отношениями, без порядков. Порядок задается самим пользователем. Это называется сортировкой строк и столбцов. И дальше мы получаем то, что в английском языке называется chat. Термин очень веселый в том смысле, что его надо отличать от графика, да, graph, да, и от диаграммы, diagram. Понятно, что возникло еще слово plot. И, естественно, русский же организм chart, я его прям по-русски написал. Почему? Потому что мы всегда любую табличку, слева, да, можем представить теперь в виде некого стандартного графического образа, которые каталогизированы и стандартизированы. И вот это было в свое время супермегапрорывом на границе где-то 2001-2005 года. Почему? Потому что дальше мы говорим, что есть некие основания для этой стандартизации. Основания какие? В основном как раз решаемые задачи. То есть сравнение, установление отношений, распределение, связь с компонентами внутри и так далее. И возникают несколько изводов этой стандартизации. Мне, например, нравится вот Абеловский, который говорит, что как раз в зависимости от того, что мы хотим, мы таблицу, то есть объектно-признаковые данные, смотрим в каком-то из стандартных графических вариантов. Можно их считать нотацией специализированной. Почему? Потому что мы имеем алгоритмы выбора соответствующей нотации. То есть, что мы хотим посмотреть в данных на основе какой-то таблицы? То-то, то-то, то-то. Выбрали. И вот таких алгоритмов, да, я знаю стандартизованных для биосистем порядка десятка. Возможно, их больше, просто вендоров основных биосистем не так много. И самое интересное, что гуманитарии пошли сюда же, но совершенно с другой стороны, и как раз, как обычно, относительно бессмысленно. Почему? Потому что никакой там периодической системы, конечно же, нет. Но им все хочется систематизировать дополнительно по каким-то странным критериям, и поэтому они часто рисуют подобные вещи. Что еще важнее, сами по себе графические образы могут отличаться, и есть значимые различия, есть незначимые. И коллеги достаточно давно, как раз в начале 2000-х годов, сказали, а давайте мы значимые различия как раз нормально стандартизируем, а незначимые отдадим на то, что назвали стилем, стилем графического изображения. появились каталоги один из самых известных до дата весь каталог где по сути мы говорим что будет признаками что будет объектами а поскольку мы же все-таки не саму таблицу рисуем какой-то графический образ делаем где будет здесь агрегация и получается что это вообще забыл просто убрать вот для основных современных экосистем появилась, и вот для нас это очень важно с позиции АГИ. Почему? Потому что мы получаем некоторую алгебру в визуализации, и самое удобное на текущий момент, это, конечно же, заиграем ее в графикс. Вот она. На ее основе сделан ggplot, на ее основе сделан let'splot, на ее основе сделана еще целая куча всего. и она реально аддитивна, то есть все команды представляются плюсиками, да, мы говорим, нарисуй мне что-нибудь плюс то-то, плюс то-то, плюс то-то, и получается какая-нибудь сумасшедшая вещь. Почему? Мы начинаем с координатных систем, дальше фацетов, статистики и так далее, а компьютер начинает снизу и говорит, что у нас есть такие-то данные, мы к ним применяем эстетики, потом шкалируем, потом как раз превращаем в геометрические образы и так далее. То есть мы на это смотрим сверху, а компьютер — снизу. И в любом случае, это на любом этапе может быть представлено той самой таблицей или объектно-признаковыми данными. И дальше как раз мы говорим, что ура, мы теперь можем данные, а это как раз та самая таблица, превратить в какую-то картинку. И стандартно это развивается уже больше 10 лет. Что особенно интересно, у нас есть прям-таки реализации готового gg плота, а еще интересней современная реализация JetBrains, который, кстати, нас покинул, гады такие, да, но тем не менее они сделали Let's Plot, которым сейчас очень удобно пользоваться. Почему? Потому что он привносит новую струю в реализацию, играемая в графикс. то есть он несовместим с гагаплотом, но тем не менее абсолютно все то же самое. Мы берем матрицу какую-то, таблицу, и как раз применяем к ней аддитивно вот эти команды через плюсик и получаем картинку. Естественно, если мы понимаем, как это делается, мы хорошо можем интерпретировать соответствующие картинки. Причем, да, если на любую щелкнуть, да, то можно посмотреть, да, стандартные примеры, как они получаются, и они все очень хорошо интерпретируются. И всегда можно понять, что было исходными данными, вот эта вот дата. И окончательно тогда что получается? Мы такие говорим. Ура! В современных всяких языках скриптовых и языках склейки у нас появляются стандартные варианты, которые вываливаются в инструменты, позволяющие скриптовать графику, но на входе и при интерпретации это те же самые таблицы объектно-признаковой данной. При этом их развелось огромное количество. Здесь, наверное, примерно половина из известных, такие особенно слухут. Да, ведь с одной стороны Matplotlib, да, с другой стороны JavaScript-овский, а снизу суперэффективный OpenGL-овский. И мы говорим, что сейчас есть две очень больших проблемы, которые потихоньку начинают расшивать. Почему? Потому что именно на уровне антологизации управления метаданными и как раз объектно-признаковыми данными, как таковыми в некоторых обычных революционных моделях, мы говорим, у нас теперь нормально должны быть представлены данные, а не просто одна большая таблица. И как раз мы говорим, а давайте все это еще соптимизируем, как Кот завещал, что у нас нормальные операции есть, логические, более сложных порядков, да, у нас есть эффективная самопорисовка и так далее. Потому что сейчас, на самом деле, если решать конкретную задачу, особенно сложную, например, особенно в динамике, это ужас-ужас, но потихоньку решается. В данном случае как раз мы должны пройти мимо обязательно понятия DataFrame, который и представляет веществление объекта признаковых данных в том виде, в котором они должны обрабатываться аналитическими алгоритмами и прорисовкой. Самый известный наверняка все знают, да, это Пандас, но он убогий, и сейчас сам Пандас перешел на Апачеру, которые позволяют эффективно хранить это дело в памяти, да? А мне, например, больше нравятся современные изводы типа Polars, VIX и так далее. В чем смысл? В том, что появился универсальный интерфейс для работы с произвольными объектно-признаковыми данными, какие бы они ни были. И, соответственно, все, например, библиотеки прорисовки, которые это поддерживают, принимают любые DataFrame. И дальше мы просто уже сравниваем, какие DataFrames лучшие по скорости, по выразительной силе, по дополнительным командам, по агрегации, по времени и так далее. А методом прорисовки и методом загрузки, то есть, например, с баз данных из CSV-файлов, из JSON-файлов и так далее, это все объектопризнаковые данные, совершенно без разницы. Ну и наконец, да, тут вот как раз всякие примеры. И пример как раз автоматической прорисовки с выбором любого варианта того, что мы хотим из объекта признаковых данных, который специально сделали для динамики. Он изначально поддерживает время. Даже первый пример, прям на сайте, да, это в динамике. Но самое веселое, что мы выбираем как раз какой-то из вариантов стандартизованных представлений графических, дальше выбираем, перетаскивая из объектно-признаковых данных признаки, и говорим, что у нас будет, что цветами будет, что будет агрегатами, что будет разделением, сплитом, партишеном, что будет группировкой. И это сейчас настолько стандартизовано, что во что во все BI-системы. Как? А появляется это, мы пропустим. Да, это нам не так важно. Дэшбординг. Дэшбординг — это то, как стала называться область преобразования объекта признаковых данных в поддержку принятия решений лицом принимающих решения. Причём по-русски оно так теперь и называется — дэшбординг. Отмечу, что классический дэшбординг — это как раз настройка на стандартизации графических образов стандартных таблиц. Но, естественно, мы можем очень по-разному всё это делать, и главное, у нас появляется возможность абсолютно идентично подходить к построению любых типов отчётов в дэшбординге, да, дескриптивных, еда, да, до любых там комбинированных, в первую очередь, прескриптивных. И, что самое веселое, как раз туда теперь встраивать искусственный интеллект, который, зная исходные представления объектно-признаковых данных в виде интерреволюционной модели, позволяет нам автоматически что-то визуализировать. В этом смысле, если хотите очень круто удивиться, имеет смысл посмотреть что-нибудь типа Майкрософт Лида. Почему? Потому что лидовцы сделали и довели до ума, вот прям на гитхабе лежит, что автоматический генератор визуализаций поверх революционной схемы. который описывается естественным языком. То есть мы имеем революционную модель, он ее читает, мы имеем написанный нами кусок текста, типа «покажи-ка нам взаимоотношения между, не знаю, мужчинами и женщинами в Калининградской области», и он ее строит. Вот как он это делает. И как раз примерно то, что получается, можно посмотреть в их статье или, например, в их туториале. И это как раз вообще работает только за счет полной унификации объектно-признаковых данных как на уровне представления, так и на уровне базовой аналитики, так и на уровне визуализации. И вот он хлобысь сам рисует все это. То есть мы у него текстом просим, Сейчас, где мы тут писали, вот гистограмма там того-то сего-то, да? И он нам рисует. Причем рисует очень-очень сложные вопросы и достаточно редко пока ошибается. Посмотрим, что дальше будет, но, наверное, еще реже будет ошибаться. В результате это уже назвали VisOps. И поэтому теперь появились уровни, да, DevOps, да, MLOps, и теперь VisOps. Ну, естественно, DataOps. опять-таки только за счет того, что мы абсолютно универсализировали методы работы с объекта признакомыми данными. Ну и, наконец, мы все это встроили в единые системы. Очень хороший референс это Microsoft Power BI, в который, кстати, встроены, да, и графы, да, и встроены революционные модели, и все на свете. И вот как раз ответ на тот вопрос. Работа с динамическими данными, даже с точки зрения визуализации изменяющихся данных, без каких-то дополнительных, например, оптимизационных алгоритмов, очень сложная вещь. Почему? Да, как только появляется ось времени, то вопрос появляется до агрегации, линейности, до самих отметок времени и их валидации, да, и, наконец, самой важной суммаризации свойств событий в этом времени. И вот тут тоже идет где-то примерно 15 лет назад, а может чуть позже, революция, которая, с одной стороны, стандартизировала все, что касается отметок времени, осей времени. Смотри, ISO 8601. В современных информационных системах, если что-то сделано не в ISO 8601, такую систему лучше выбросить, чем работать с ней, да? А с другой стороны, у нас появились примерно вот такие интересные каталоги и соответствующие там статьи, книжки и так далее о том, как выбирать визуализацию темпоральных данных, которые опять-таки объектно-признаковые данные, просто одним из разрезов становится время. Ну и естественно все на ВСО 7601. Отмечу, что сайт сам по себе просто изумительный для посмотреть. Почему? Потому что на входе-то все одно и то же. А с какими способами можно это представить? Ну, они же написали книжку очень хорошую, визуализация временных данных. и как раз вот сколько у них уже накопилось всяких примеров. При этом, щелкая на пример, мы видим, откуда взят, да, вот референс, и можно сразу посмотреть какой-нибудь вариант из уже следующего там поколения. Ну и как раз прокрутиться и как раз посмотреть, да, с какой целью мы это делаем, по какому времени работаем, с какими данными работаем, да, и чем представляем. В принципе, да, это замыкает все, что мы говорили от самого представления в языке, а потом в компьютере, исходных контекстов, они же релационные отношения, и, соответственно, есть общая теория relational как раз formal concept analysis. и как раз вплоть до визуализации, которая сейчас стандартизована до уровня, когда, имея описанную революционную модель, мы автоматом можем с помощью искусственного интеллекта породить до стандартной прорисовки. Понятно, что здесь осталось не как раз охваченным кусочек по именно работе с антологиями, но он оказался реально очень большой. Я лучше отдельно расскажу. И как раз кусочек про естественный язык и сверхбольшие языковые модели, который у меня там в самом конце был заявлен. Но это тоже оказался очень большой кусок, поэтому мы сейчас от исходного представления до визуализации именно данных. Спасибо. 

S05 [01:17:39]  : Алексей, спасибо огромное. У нас там осталось несколько вопросов, но я предлагаю пойти сначала, пропустить то, что были вопросы. про истину ответили. Вот про замкнутость. Был вопрос от Бориса вначале. У вас модель всегда замкнута, как геометрия, или она открыта? 

S03 [01:18:02]  : Это зависит как раз от той онтологии, на которую мы ссылаемся. Если у этой онтологии исходно принцип замкнутого мира, то замкнутая. Если она умеет работать с открытым миром, то всё открытое. Потому что самим объектно-признаковым данным без разницы. То есть мы всегда можем либо шкалу расширить и изменить, либо как раз добавить какой-то уровень представления объектов, поскольку уровень абстракции есть, и им без разницы. 

S01 [01:18:31]  : Новый объект будет появиться. Ну, естественно, объекты всегда появляются и исчезают, поэтому у нас есть отдельно схемы отношений, да, отдельно кортежи в этих отношениях. Или то же самое, что в контекстах, да, вот здесь появляются как раз отдельно новые шкалы, да, потом бенаризация этих шкал, ну или, например, в интервальных структурах там не бенаризация, а более сложные отношения, и сами объекты. потому что как раз мы на уровне вот этой верхней штучки схемы можем сами изначально некие фиксировать отношения и сказать например что если у нас там большая планета то она далеко от солнца и мы это типа не можем нарушить если нарушили это значит какая-то парадокс и так далее А можем как раз не накладывать таких ограничений и заниматься датамайнингом, то есть добычей данных, на самом деле добычей гипотез, из контекста и говорить, о, тут появляется импликация, что если планета большая, то она далеко от Солнца. И поэтому это как раз вопрос не к самому этому представлению и работе с ним, а к ссылке на онтологию. То есть, если вот этот сайз ссылается на онтологию, где есть элемент размер, да, и сама онтология поддерживает концепцию открытого мира, да, всё будет нормально работать. Если не поддерживать… – Онтология запнутая. 

S01 [01:19:51]  : Онтология запнутая. 

S03 [01:19:54]  : – Какую хотите. 

S01 [01:19:56]  : Новое понятие или объект может возникнуть в ходе обработки или привносится извне? 

S03 [01:20:04]  : – Вот это правильный вопрос. Он может привноситься извне, если как раз онтология поддерживает концепцию открытого мира, либо только в процессе обработки. Почему? Потому что если мы ссылаемся на онтологию, которая закрытая, и объект какой-то появился, у которого нужное нам свойство не в этой онтологии, то мы ничего не сделаем. 

S01 [01:20:24]  : А если изне, то как? У него могут быть другие правила обработки. 

S03 [01:20:30]  : В том-то и дело, что нет. Здесь всё, что можно с ним сделать, я уже рассказал. То есть, можно только сопоставить объект с каким-то образом преобразованным элементом шкалы, и всё. 

S01 [01:20:43]  : Например, кварки. Появился цветовой заряд. Не было заряда. 

S03 [01:20:49]  : Мы добавляем шкалу цвета. Здесь появляется там color. И спокойно проставляем галочки. 

S01 [01:20:56]  : То есть мы меняем антологии извне. Это не в процессе обработки данных. 

S03 [01:21:02]  : А, в этом смысле, да, нет, в процессе обработки данных у нас то, что есть в тех контекстах, ну или реляционных отношениях, да, которые уже есть, то есть, ничего другого мы, естественно, ниоткуда получить не можем в процессе обработки. Все, я теперь понял. 

S05 [01:21:19]  : Спасибо, Алексей. Да, вот вопрос у меня был про нечеткие, вероятностные и неаксиматические логики. Не уходя с этой таблички или, может быть, на ее основе, можете раскрыть все-таки, как вы оцениваете то, что, допустим, мы либо можем с некоторой точностью или с некоторой определенностью, неопределенностью осуществлять измерение, 

S03 [01:21:48]  : вот а также с тем что у нас просто могут быть разные распределения в части и наблюдения тех или иных объектов мы по сути говорим что теперь здесь будет не галочка да какой-то сложный объект для этого естественно сама математика переходит от отношения вот этого и да когда просто объект имеет признак к чему к узорной структуре Например, самый простой вариант, который здесь как пример приведен, это интервальная узорная структура, где мы говорим, у нас появляется интервал значений, соответственно, по сути, два числа в каждой ячейке. То есть, например, мы вот это измерили от 4 до 5. Дальше, естественно, мы сюда можем добавить распределение, дальше сюда можем добавить какие-нибудь последовательности, дальше сюда можем добавить графы, и так далее, и так далее. Сами операторы вот эти, да, они никак не изменяются. И как раз просто изменяется смысл, то есть интерпретация, да, этих операторов в конкретных условиях. Например, это будет не, там, минимум, да, плюс... максимум при сложении интервалов, да, а что-то еще, например, если это тут будут графы, то, например, это будет операция взятия максимального пересечения графов. 

S05 [01:23:09]  : Мы можем сказать, что у нас метрики вероятности или нечёткости могут быть разные. Мы можем любую математику навешивать. 

S03 [01:23:19]  : Главное, чтобы сохранялась вот такая штука и следующие из неё верхние и нижние грани, чтобы мы всегда работали в частично упорядоченных множествах. 

S05 [01:23:30]  : Угу. Хорошо. Спасибо. Еще вопрос был от Бориса Новикова. Какая связь моделей и реальности через классы задач? 

S03 [01:23:39]  : Это в сторону, когда мы обсуждали. Здесь, с точки зрения моделей представления, representational models, никакой связи нет. Связь появляется либо при интерпретации, к чему мы уже до этого пришли, либо связь появляется при решении какой-то задачи, то есть оптимизационной задачи или какой-то еще. И как раз это Связь, она у нас классическая на уровне граундинга, то есть заземления. Мы должны либо иметь всюду, ну, не обязательно всюду, но хотя бы где-то истинную интерпретацию, и, соответственно, бороться там со всеми стандартными парадоксами, смотри, развитие логики, да, послевоенной. Либо мы должны иметь что? Некий солвер, который для нас является черным ящиком, и у которого на входе объектно-признаковые данные, и на выходе объектно-признаковые данные. И тогда мы говорим, что этот черный ящик для нас, да, это некий агент преобразования данных. А какой у него будет граудинг, да пусть кто-то другой решает. На самом деле сейчас это очень большая проблема у студентов. Они, например, очень часто методы машинного обучения считают некой магией. Хотя на самом деле это как раз набор вот таких черных ящичков, которые одни объектно-признаковые данные преобразуют в другие объектно-признаковые данные. И им нужен обязательный граундинг. То есть ты должен снабдить эти ящички откуда-то извне как раз ссылками на онтологию для объектов и признаков. А студенты это сплошь и рядом забывают. Или для ни всего делают. И в итоге получают странные результаты и думают, что это такое, и какая у них интерпретация. Самое страшное — это то, что стандартные информационные системы, начиная от Excel того же, который уже упоминали, они автоматически не заставляют вас проставлять единицы измерения. 

S05 [01:25:33]  : Спасибо. Еще вопрос от Виктора Казаринова. Как разделяются собственные и относительные признаки в математических моделях, представляемых вами? Например, наличие двух рук, собственный признак, рост человека относительно другого человека, относительный в моей терминологии. 

S03 [01:25:49]  : Никак. Главное, чтобы была процедура вычисления. Это как раз вопрос, который всегда в начале курса обсуждается. То есть мы говорим, что вот эта шкала, она каким-то образом задает соответствующее отношение между объектом и признаком. И надо, чтобы эта шкала была вычислимой. Вот. Все. Другого ответа у нас нет совсем. Почему? Потому что если шкалу сделали неучислимой, то она не может породить никакого признака. А если она учислимая, то она автоматом все это породит. 

S05 [01:26:24]  : Спасибо. Борис, я вижу Вашу руку, но давайте еще два вопроса из YouTube возьмем. Спрашивает пользователь Яф Яф. Во-первых, используются ли в качестве признаков отношения между объектами, поведение объектов? Если да, то как их представляют в формальном контексте, особенно НР-ные отношения? 

S03 [01:26:45]  : Вот замечательный вопрос. Ответ сразу нет. Но раскрытие. Когда мы говорим, что у нас есть как раз базовая концептуальная модель, надо понимать, что мы живем, когда с объекта признаковыми данными, они у нас разной природы. И соответственно, если мы посмотрим даже самый простой, например, вариант ER-диаграмм, В нём у нас есть прямоугольнички и ромбики. Ну, понятно, что много чего ещё есть, но это главное, да? Объекты и отношения. Отношения порождают признаки. При этом понятно, что сами отношения порождают признаки как? Они же должны вычисляться. И для этого в модели внесены атрибуты, то есть, собственно, признаки. Но это признаки и объектов, и признаки отношений, то есть связей. Соответственно, да, у нас никакого между ними взаимодействия как бы нет. И это, кстати, краевольный камень вообще всей этой конструкции. 

S05 [01:27:45]  : Хорошо. Следующий вопрос. Используются ли векторные логики, в скобках Аршинские, вместо нечеткой логики? 

S03 [01:27:52]  : Я на практике ни разу не видел, а статьи видел. Поэтому насчет используется ли кем-то, возможно, мною нет. 

S05 [01:28:01]  : И еще вопрос, тоже на самом деле я удивляюсь, что мне в голову не пришел. Есть ли метода вывода отрицательных понятий? Отсутствие признака. 

S03 [01:28:13]  : И как вообще с отрицанием? Просто если опять на любимый пример посмотреть, то пустые клеточки Это на самом деле отрицание заполненных клеточек. И поэтому можно как раз, что делать? Можно отсюда стандартным образом, да, логически, да, начиная с логики высказываний, извиняюсь, порождать как как раз позитивные высказывания, так и негативные. 

S05 [01:28:41]  : А тогда как вы относитесь вообще к понятию отрицания в логике и в естественном языке? Это просто некоторый трюк или как это? Это просто нотация, которая позволяет описывать пустые клеточки? Да. 

S03 [01:28:55]  : То есть мы здесь специально, когда еще в 70-х годах. разговаривали про то, а что нужно из реального мира положить в компьютер, чтобы его описать, как раз к этому пришли. То есть мы пришли к тому, что кладем, по сути, только позитивные описания, считая, что все остальные становятся их отрицанием. Собственно, на этом вообще работает, ну, точнее, вся эффективность баз данных, например, да, и система управления базами данных, на этом построена. То есть у нас есть гипотеза амплостей мира, плюс как раз позитивность описаний. И поэтому, кстати, у нас в всех даже самых простых системах, которые на этом основаны, всегда есть как минимум трехзначная логика. То есть, например, в SQL, да, у нас есть истина, да, ложь, не знаю, unknown. Причем именно unknown. То есть null – это как раз денатат, который может иногда обозначать unknown, а иногда может обозначать что-то другое. Поэтому там три значения логических – истина, ложь и неизвестный. 

S05 [01:29:58]  : Спасибо. Борис? 

S01 [01:30:01]  : Да, спасибо. Ну, во-первых, я хочу поблагодарить докладчика. По-моему, очень интересный доклад. И хочу предложить свое, так сказать, философское понимание и спросить, прав ли я. Мне кажется, что это прямое развитие арифметики натуральных чисел, но только в очень больших масштабах. Когда нас интересует только счётное количество предметов, а больше про них ничего не интересует, мы пользуемся арифметикой натуральных честей. А когда у нас есть любая модель, в ней есть то, что описывается и чем описывается, и соотношение между ними. И в рамках этой модели вот такой подход позволяет синтергизированным образом обрабатывать все такие модели. При этом вопрос о связи модели с реальностью не ставится в рамках этого подхода. Я прав? 

S03 [01:31:10]  : Абсолютно. Единственное замечание, что все-таки я бы не на арифметику ссылался, а ссылался на какие-то из логик. Почему? Потому что здесь в основе всех формальных систем лежит теория множеств. и ее изводы с точки зрения дополнительных логик. Поэтому все-таки здесь нет, например, знаменитых парадоксов о вычислимости в том смысле, в котором мы работаем с бесконечными итераторами. То есть, что у нас есть единица, как первый элемент, есть генератор, увеличивающий на один, и так до бесконечности. Здесь у нас нет бесконечности вообще. 

S01 [01:31:50]  : Но актуальной бесконечности в арифметике тоже нет. 

S03 [01:31:54]  : Там есть доказательства… А, вы имеете в виду уже арифметику по модулям. 

S01 [01:31:58]  : Ну, я так глубоко не пойду. 

S03 [01:32:02]  : Я привык, что студенты могут всегда извратить любое высказывание, извиняюсь. Поэтому в данном случае я бы освободил книги. 

S01 [01:32:10]  : Меня больше интересует теория познания в этом плане. Поэтому я пошел от арифметики натуральных чисел, как наиболее старого и наиболее такого абстрактного, Пример работы неважно с какими объектами. 

S03 [01:32:29]  : Да, я бы вот сослался на common logic лучше. То есть сейчас же есть базовое описание многосортной логики предикатов первого порядка в виде как раз алгебры, XML и графики. Вот я бы на нее сослался. 

S01 [01:32:41]  : Хорошо. Просто это менее известные, менее наглядные. 

S05 [01:32:46]  : Спасибо, Борис. Еще пара вопросов подоспела с YouTube. Первый вопрос. Знакомы ли вы с работами Смирнова Сергея Викторовича? И второй вопрос, как вы боретесь с огромным количеством мусорных объектов порождаемых анализом формальных понятий? 

S03 [01:33:03]  : Очень просто, стандартным вариантом, так же как и в революционной алгебре и так далее, когда мы говорим, что у нас есть базисы импликаций, И так же как в Data Mining, когда мы говорим, что у нас есть базисационные правила разного типа с offset, и мы говорим, что всегда выставляем с одной стороны некие преграды для бесконечного роста, а с другой стороны говорим, что всегда можем воспользоваться базисом. Ну там, начиная от Байса Дюкена Гига, да, и заканчивая всякими современными там изводами. Почему? Потому что в реальности нам почти никогда не нужны сложные гипотезы. У нас есть принцип минимальности описания. принцип минимальности описания с собой тянет принцип минимальности гипотезы, и, соответственно, чем меньше объясняющая гипотеза, тем она лучше, по большому счёту. И, соответственно, на практике, если у нас, например, в гипотезе число посылок перевалило за десяток, то обычно это что-то уже очень странное. Поэтому вот на самом деле это половина ответа. Почему? Потому что есть вторая половина про именно мусорные объекты. Почему? Потому что если мы посмотрим на любую как раз матрицу, то мы не работаем с ней как с универсальным контекстом, причем уже много лет. Вот эта матрица у нас никогда не одна. у нас всегда есть то, к чему я как раз перешел, как поженить. И у нас есть relational concepts, и тем самым мы говорим, нам достаточно сделать много маленьких контекстов, которые будут увязаны друг с другом, так же как в релационной модели абсолютно, и тем самым не обращать внимание на огромные пустые куски контекстов. Это, кстати, был тоже супер прорыв с точки зрения эффективности вычислений. 

S05 [01:35:06]  : Спасибо. Еще вопрос от того же пользователя Яф-Яф из YouTube. Как учитывается прагматика концепта? 

S03 [01:35:15]  : А, это же мы только что говорили. Дело в том, что у нас нужно все, что мы здесь говорим о классах или о сущностях с одной стороны и как раз признаках или шкалах с другой стороны привязывать к антологии. Соответственно, да, прагматика учитывается уже в этой антологии. Сами объектопризнаковые данные ничего об этом не знают. 

S05 [01:35:41]  : Спасибо. Коллеги, есть еще вопросы или комментарии? 

S03 [01:35:46]  : Вот, появился в чате замечательный вопрос. Дело в том, что да, у нас, как только мы получаем что-то очень большое, мы действительно такие ощупывающие слона, и это везде истинно. То есть, будь то там в сложных моделях машинного обучения, или просто в описании паспортов людей в стандартной базе данных, это везде именно так. Мы всегда смотрим через замочную скважину на объекта признаковой данной. Мы всегда смотрим на маленькое подмножество объектов и маленькое подмножество признаков. Это вот прям в точку. И главный как раз вопрос связи системных аналитиков или системных инженеров со специалистами по анализу данных – это, а не забыли ли вы какие-то признаки или объекты? Какие-то существенные признаки или объекты. Лучше существенные, да. 

S05 [01:36:50]  : Спасибо. Коллеги, есть еще какие-то вопросы или комментарии? Владимир Смолин. 

S04 [01:37:00]  : Вопрос очень простой. А какое это имеет отношение к сильному искусственному интеллекту? 

S03 [01:37:04]  : Дело в том, что когда... Мы обсуждали с коллегами построение машин вывода, которые были бы лишены всех возможных типов галлюцинации, которых мы насчитали несколько десятков. то единственное, что смогли придумать, это как раз не просто создание какой-то универсальной машины вывода, ну на мой взгляд это вообще невозможно, да, с остальными могу подискутировать, это очень интересный вопрос, да, а единственный вариант это как раз сказать, что мы, да, какой-то набор данных Стандартным образом кладём себе в память и делаем дальше либо то, что называется нейромашиной Тюринга или её изводами, либо делаем то, что называется как раз рекурсивным хранилищем ассоциативной памяти. И пока что из всех реально работающих систем, которые борются с галлюцинациями, это то, что позволяет как раз их исключить на корню. То есть мы всегда можем в качестве интерпретации результата сослаться на конкретную ячейку в конкретном контексте. 

S04 [01:38:13]  : Вы считаете, что это основная проблема искусственного интеллекта? 

S03 [01:38:18]  : Нет, конечно. Разговор начался с того, что люди не очень понимали, как слотовая структура репрезентации объектов реального мира работает. Любой искусственный интеллект, который претендует на общность, Он как раз обязан предлагать универсальные решения о репрезентации такого типа объектов хотя бы. 

S04 [01:38:43]  : Это интересная трактовка, но моя трактовка немножко другая. Если мы работаем с данными, которые передал машине человек, то эта система уже не является сильным искусственным интеллектом, потому что она с другими данными работать не может. Я правильно понимаю, что она работает с данными, которые ей должен дать человек? 

S03 [01:39:04]  : Я, например, сейчас работаю над системой, которая вообще ничего от человека не берет, а только сенсоров физических. 

S04 [01:39:10]  : Это прекрасно, но сенсоры и параметры, которые она обрабатывает, определил человек. То есть она не сама выбрала эти параметры, не сама выбрала эти объекты, это чисто человеческие прерогативы. 

S03 [01:39:22]  : Значит, это как раз настолько глубокий вопрос, что если мы, например, скажем, что у человека есть прерогатива выбирать какие-то параметры, то на самом деле они заданы всей историей цивилизации человеческой, да, и, соответственно, у человека нет никакой воли. А можно сказать наоборот, у человека есть, да, свободная воля, и, соответственно, можно попытаться ее передать компьютеру. Вот, я бы туда в принципе не лез, потому что когда мы начинаем говорить о том, что первично, а здесь как раз же о яйце и курице вопрос, то мы заходим в область, которая не моделируется пока ничем, с чем бы я мог столкнуться. 

S04 [01:39:58]  : Я понимаю, что по названию вашей доклады, что мы не знаем, как это делать, соответственно, никто не знает. Я правильно вас понимаю? 

S03 [01:40:05]  : Да, пока никто не знает из тех, кого я слышал. 

S04 [01:40:07]  : Спасибо, я оценил ваш юмор. 

S01 [01:40:12]  : А я бы дискутировал о свободе воли у человека и нужности этого искусственному интеллекту или недопустимости. 

S03 [01:40:26]  : Ну это к Антону скорее вопрос. 

S05 [01:40:28]  : Я не знаю, Борис, это имеет отношение к сегодняшнему докладу? 

S03 [01:40:32]  : Частично, потому что мы входим в область как раз о какой из онтологий по сути нам привязывают шкалы и классы, ну или там сущности. самому сразу говорим типа можно ли создать например разные интерпретации текущих объекта признаковых данных которые в одной системе до там человечество уничтожит а в другой наоборот помогут развитию данным не тепло не холода от этого хорошо борис какой тогда ваш тс 

S01 [01:41:06]  : Мой тезис, как всегда, что интеллект – это способ решения задач, а постановки задач связаны с психикой или сознанием, а психика или сознание связаны с телесностью и социальностью. И нам надо не допустить телесности и социальности искусственного интеллекта. Тогда он будет служить людям, а иначе он начнёт служить себе. 

S03 [01:41:38]  : – Это да, в соседнем чате, кстати, который уехавший Иван, говорю, коллега ведёт, там как раз обсуждают этот аспект уже очень много, и за этим следить интересно, а участвовать прям не хочется. 

S05 [01:41:51]  : Кстати, насчет соседних чатов. Да, я на самом деле тоже хочу поблагодарить докладчика. Мне было очень интересно. В соседнем чате шла дискуссия в начале доклада по поводу того, что нашлось несколько спикеров, которые высказали, что наш сегодняшний докладчик пересказывает их теорию чуть ли не своими собственными словами. на что я смог только прокомментировать, что у великих людей мысли сходятся, но опять-таки одно мало дело иметь теорию в голове, а другое дело излагать ее словами, а еще и фиксировать на бумаге в книгах. 

S03 [01:42:31]  : Помните, с чего я начал? Я сделал реверанс в сторону того, что использую только один извод терминологии. И вслед за Сергеем Олеговичем Кузнецовым говорю, что, например, французский мне там нравится меньше. И, соответственно, здесь в самом начале, сейчас, где определение? Определение, что мы будем использовать, например, немецкую нотацию, которую с Гантером согласовали. То есть, соответственно, Филли, например, может обидеться. Вот еще много кто может обидеться, но при этом сам по себе потом алгоритмический аппарат, он от этого вообще никак не зависит. 

S05 [01:43:08]  : Спасибо. Есть еще вопрос у Владимира Фролова. Владимир, пожалуйста. 

S00 [01:43:14]  : Здравствуйте, было очень интересно послушать. У меня вот такой вопрос, я определенные проекции делаю на мое понимание головного мозга. Вот смотрите, вот эти вот таблицы, они как бы большие, наверное, данных туда входит очень много. Со временем, чтобы как-то сделать какое-то правильное решение, исходя из вот такого массива данных, может потребоваться очень большое время. Нет ли такого подхода? Давайте эти большие данные приведём к какому-нибудь виду, чтобы как-то обобщить это всё, чтобы это было более компактно, чтобы понять какие-то закономерности, какие-то возникают, может быть, каких-то данных для чего-то нет. Мы как-то обобщили, перешли к другой схеме, с которой более удобно работать. которая может быть даже какие-то выявила закономерности и считает их верными. И уже работать в таком представлении суммарном. Есть такой способ. Давайте все события, какие мы видели, запомним и при принятии решений возьмем и будем их перебирать и максимум информации получим, но мы очень большое время затратим. Это хорошо, но лучше перейти как бы сделать какую-то выжимку в голове, например, чтобы какие-то построить понятия, какую-то схему упрощенную, которая более быстро работает. Вот в связи с вашим подходом, есть ли какая-нибудь вот такая вот ужимка, что ли, вот этих всех таблиц во что-то новое? 

S03 [01:45:08]  : Ну, в общем, на практике, да, у нас есть Data Mining. Я вот прямо в Википедии открыл, да. Data Mining, он прям по определению, да, процесс выдирания и обнаружения шаблонов в больших наборах данных. Где? Это, кстати, страшный миф. наборы данных — это как раз объектно-признаковые данные, не более, не менее. И это огромный доизвод о том, как на основе импликации, на основе ассоциативных правил, на основе как раз кластеризации, бикластеризации, многомодальной кластеризации и так далее, находить как раз что-то, что минимальными усилиями описывает большие данные. Более того, у нас как раз же есть термин уже давно, Big Data. А почему он есть? Именно потому, что сейчас было задано. Более того, у Big Data есть 5W с точки зрения техники. И 5W знаменитые. Volume, Velocity, Velocity и Verity, они как раз никуда не даются никогда, они всегда есть. И понятно, что мы, например, когда строим сами понятия, мы об этом уже упоминали, используем, например, самые как раз дистинктивные. Это, кстати, прям отдельно надо большой кусок. Почему? Потому что, например, если мы породы кошек устанавливаем, то некоторые могут оказаться там почти неразличимы. Зачем нам такие? Давайте сделаем, чтобы они были различимы. Если мы себе сделаем 20 различимых хорошо понятий и 30 плохо различимых, то, скорее всего, эти 30 будут хуже, чем эти 20. И поэтому, одновременно работая с гипотезами и минимальными описаниями, плюс как раз специальной переработкой понятия на основе их дистинктивности по объему и содержанию, мы уже очень серьезно экономим как объёмы памяти, так и объёмы внимания. Но Борис вам не согласен, да? 

S01 [01:47:10]  : Не согласен. Всё зависит от задач. Я когда-то занимался филателлией. Мельчайшее различие в зубчиках меняет цену марки в тысячу раз. 

S03 [01:47:27]  : Спасибо большое за ответ. Здесь вопрос очень интересный. Почему? Потому что это уже как раз специфика задачи. Зато наверняка вообще никак на это дело не влияет температура марки. 

S01 [01:47:41]  : Температура не влияет. 

S03 [01:47:43]  : Поэтому, да, в зависимости от задачи у нас разная значимость, то есть, сигнификанс тех или иных признаков и, соответственно, тех или иных… Поэтому модель главная, слова наиболее универсальные и главные можно пренебречь. 

S01 [01:48:01]  : чем можно пренебречь для этого класса задач, а что наоборот существенно для этого класса задач. И это меняется от одного класса задач к другому. 

S03 [01:48:12]  : Да, abstraction is all we need. 

S05 [01:48:15]  : У меня появился вопрос и комментарий. Комментарий вот вы вспомнили про бигдату, дату упомянули, а я вспомнил, поскольку вот увидел, что вы в Штюнберже работаете, Я тоже имею бэкграунд в геофизике и геологии. И я всегда, когда заходит речь про бигдейту или бигдату на всяких тусовках, периодически упоминаю, что бигдата появилась в геофизике еще лет 50 назад. Только никто её бигдата не называл, но все эти проблемы, которые сейчас обсуждаются, они там стояли в полный рост и никто не говорил про то, что это искусственный интеллект. Все просто решали эти проблемы. Не все, но ряд проблем, с которыми сейчас сталкиваются мышелёнеры, они тогда были обыденностью. А вопрос у меня такой. Вы как раз заговорили про дистинтивность, а я, по-моему, года полтора назад здесь сделал как раз доклад про естественную классификацию, кластеризацию и метрики кластеризации. У вас есть какая-то позиция или опыт поделиться с точки зрения того, каким образом С практической точки зрения меня интересует, каким образом определять оптимальные параметры кластеризации, число кластеров, какие есть формальные метрики того, что мы нашли именно балансированные параметры шкалирования. оптимальное число мастеров, метод минимального расстояния, коэффициент силуэтаж. И что на эту тему скажете? 

S03 [01:49:51]  : Здесь я сразу сошлюсь на Бориса Григорьевича Мюркина, потому что считаю его одним из лучших объединительных практик истории в этой области. И что, в принципе, не поставив задачу, это все колдунство. А самих методов, которые у меня каталогизированы в аннотике, их порядка 50, по-моему, что ли. То есть это намного больше десятка. Почему? Потому что у нас есть очень разные постановки самой задачи кластеризации. То есть у нас же есть кластеризация с разным пониманием того, что в ней является измерениями. смысле размерностями, очень разные постановки того, а нужно ли нам как раз смотреть на выбросы или на средние. То есть тот же Каминс — это, например, беда всех студентов. И, соответственно, отсюда идут изводы робастой статистики разных типов и как раз робастой кластеризации разных типов. И отдельно идет очень важный кусок, который связан с мультимодальной кластеризацией, когда мы несколько множеств параллельно кластеризуем. Почему? Потому что на практике он обычно самый важный, если мы правильно связали эти множества. А множество связывается по-разному, и там структуры графов связей могут быть произвольными на самом деле. И опять-таки, не поставив задачу и не сказав, какому классу, например, двудольный, тридольный граф и так далее, либо граф произвольного вида связывает наше множество, вообще ничего не скажешь. Единственное, что более-менее общее, с моей точки зрения, это имха. Имха такой прям. Это методы понижения размерности. Они вполне могут идти как стандартный набор тех методов, которые можно ко всему применять. 

S05 [01:51:34]  : Спасибо. И еще два вопроса подоспело из YouTube. Первый вопрос. Как учитывать темпоральное изменение признаков объекта? И тут же второй вопрос. При темпоральном изменении признаков объекта меняются концепты? А, вопрос. При темпоральном изменении признаков объекта меняются концепты или объект переходит в объект другого концепта? 

S03 [01:51:55]  : Вот, очень хорошо. Значит, да, на оба варианта. Почему? Потому что все зависит от того, как мы порождаем новые признаки. Мы можем новые признаки породить… Ой, я эту самую уже закрыл, да? Значит, ну просто тогда эту самую картинку откроем, да? Значит, мы можем сказать, что, например, у нас на какую-то планету налипает материал, он становится все больше и больше. И вот вопрос, да, что мы делаем с признаками? Есть два основных варианта. Первый вариант — мы добавляем к признакам отметку времени и становится у нас стандартное, любимое всеми в базах данных, версионирование. То есть у нас появляется размер на такое-то число, например. Вопрос, если у нас есть на размер такое-то число, да, имеет ли смысл объединять признаки за разные числа, ну, за разные даты? Обычный ответ в большинстве приложений не имеет смысла, и тогда как раз мы говорим, что у нас остаются понятия, да, и как раз объекты переходят из одного в другое естественным образом. А вот другой вопрос есть. Это мы рассматриваем 4D-объекты, то есть 4D-экстенциализм, как он есть, и говорим, что у нас есть жизненный цикл. И здесь мы переходим на очень тонкий лёд. Почему? Потому что, скорее всего, я в годик больше похож на любого другого ребёнка в годик, чем на себя текущего. Извиняюсь. И там нужно как раз смотреть, какая задача как раз все-таки решается. То есть по умолчанию обычно выбирается первый вариант. И как раз версионирование приннаков – это классическое версионирование, которое говорит, что было на момент времени в прошлом. А вот как раз 4D экстенциализм и всякие жизненные циклы объектов, они должны очень серьезно зависеть от контекста. Спасибо. Надеюсь, ответил, да. Может, там еще несколько смыслов можно выдрать из вопроса. 

S05 [01:53:54]  : А, кстати, как вы относитесь к идее, к тому тому, что мы опять-таки в определенной постановке задачи можем рассматривать различные объекты в различные периоды времени под классами одного и того же объекта? 

S03 [01:54:09]  : Вот здесь я бы вообще не рискнул отвечать какое-то одно предложение, один постулат. Почему? Потому что очень сильно начинает это зависеть от того, как мы проводим классификацию по времени и по пространству. как строим халархии и таксономии, и главное, как потом во времени трактуем жизненный цикл объекта с точки зрения его возникновения и исчезновения. То есть, например, даже когда я себе сам говорю, то я могу говорить, когда я был ребенком, юношей, подростком. Вот юноша, подросток, ребенок могут быть понятиями? Конечно. Это понятия связаны со временем? Конечно. Они меня определяют, если я добавлю идентификатор себя, например, номер паспорта, то будут определять. Будет человек такой-то, когда он был ребенком. И вот в такой постановке я даже работал с системой, которая так умела логически мыслить. В ней был движок вывода, которым была темпоральная логика, которая, по сути, занималась версионированием понятий. Но я бы это не обобщал. То есть вполне возможно, что кто-то сейчас скажет, что на самом деле надо там делать всё намного лучше. И главное, что когда я статьи на это дело читал, по динамике всякой, то здесь самое печальное, что изводу слишком много. То есть я не рискну полностью давать какие-то комментарии к этому вопросу с точки зрения полноты. Но единственное, что я могу сказать, что я прям занимался в том числе и кусочками реальной практики. И, например, здесь у меня в конце уже есть всякие там очень интересные вещи. Вот, например. то есть вот у нас есть графовая модель, да, причем там вполне солидной системы, да, она вот во времени изменяется. Как с ней работать с точки зрения того, что отдельные компоненты там вместе образуют подсистемы? Можно априори задать подсистему и сказать критерии принадлежности компонента под системе, а можно задать наоборот некое свойство набора объектов и сказать, образуют ли они подсистему или нет. На самом деле в итоге будет одно и то же, но representation абсолютно разный. Поэтому это такое широкое поле, здесь надо динамику обсуждать полноценно. Хорошо. Но это очень интересное поле. И самое сложное, кстати, в реальной деятельности. Отмечу, что с 2016 года, после того, как появилась, ну, прошла, точнее, революция во временных рядах, с точки зрения тех же там матричных профилей и прочего, да, совершенно по-новой у нас теперь есть механизмы-алгоритмы работы с такими, с такого вида гадостями, да, и, в принципе, это может быть отдельной тематикой, а может ли и, да, оптимизировать работу с динамическими системами. Вот у меня сейчас есть предположение, что уже может быть и может, особенно с учетом того, что у нас появились первые Foundation Model для работы с временными рядами. Я прям уже сам тоже посмотрел. То есть если мы скажем LLM Foundation Model и как раз Time Series, можно будет очень круто удивиться, потому что на гитхабе, уже на гитхабе, да, есть вот такая вот крутая штука. И здесь есть шикарнейший обзор, вот такой, с очень красивыми картинками. Если он сейчас нажмется, будет очень интересно. Нажался, но что-то не открывается. Ну и дальше как раз, видите, сколько всего на эту тему уже. То есть народ этим очень сильно сейчас интересуется и пытается делать. Ну, почему она не открывается? О, открылась! Ура! Видите, какая прелесть будет. 

S02 [01:58:18]  : О! Круто! 

S03 [01:58:24]  : То есть мы говорим, что у нас временные и пространственные признаки плюс координаты, ну координаты тоже признаки, могут участвовать в создании слов и предложений естественного языка, и более того, в обратную сторону это вполне может быть как описание задачи с учетом geospatial или temporal spatial data. И коллеги тут уже даже вводят то, что о, мы типа идем к Foundation Model, которые автоматически учтут время, но надо не забывать, что это нужно правильно проверять. А это ведь 2001 год еще, 2021, да? Вот в прошлом году вышло продолжение этого суперобзора, и там как раз народ уже прям эксперименты всякие интересные ставит. 

S05 [01:59:16]  : Здорово. Алексей, спасибо вам огромное. В частности, во-первых, действительно очень интересно и близко, я думаю, не только мне, но и многим. Во-вторых, в ряде докладов у меня возникает мысль о том, что жалко, что до сих пор нет софта, который из видеопотока выдергивает ссылки. Но сегодня вот это ощущение прям зашкаливало. 

S03 [01:59:42]  : Вы, если напомните, какие-то отдельные вопросы, да, я все ссылки... У меня часть ссылок, да, вот, да, спасибо. 

S05 [01:59:47]  : Часть ссылок я на ходу успевал, значит, нагуглить и сбрасывать. Ну и просто презентацию отдам, да. В наш чат. 

S03 [01:59:54]  : А что-что? Презентацию тоже отдам. 

S05 [01:59:56]  : Да, если отдадите презентацию, я думаю, это будет многим полезно. Спасибо вам огромное, что пришли. Коллеги, всем, кто участвовал, спасибо за интерес, за опросы. Да, спасибо. 

S03 [02:00:07]  : Замечательно и всем до новых встреч спасибо коллеги алексей спасибо до свидания я вам в чат кинул последнее да спасибо здорово до свидания коллеги всяческих успехов 







https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
